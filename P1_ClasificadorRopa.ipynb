{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv0UorTVdUhz"
      },
      "source": [
        "### Grupo B04\n",
        "### Miguel Egido Morales, Alfredo Robledano Abasolo, Ana Robledano Abasolo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWbYb_Ejqlms"
      },
      "source": [
        "# P1 AA Configuración y Entrenamiento de una Red de Neuronas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYK5LlXYszma"
      },
      "source": [
        "Utilizaremos la **biblioteca Python Keras** para **clasificar** artículos de ropa.\n",
        "\n",
        "**PROBLEMA:**\n",
        "- Clasificación de imágenes en escala de grises de prendas de ropa (28 x 28 píxeles) en sus 10 categorías (de 0 a 9, guardadas en etiquetas).\n",
        "- Usaremos 60K imágenes de entrenamiento y más de 10K imágenes de prueba\n",
        "- El conjunto de datos MNIST está precargado en Keras en la forma de un conjunto de cuatro matrices Numpy\n",
        "- Algunas muestras\n",
        "- Tenemos las siguientes categorías o **clases** del problema de clasificación de ropa: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot.\n",
        "- Los \"puntos de datos\" son **muestras**\n",
        "- La clase asociado a una muestra específica se llama **etiqueta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt69U75udUh1"
      },
      "source": [
        "Importamos el paquete tensorflow que contiene a la librería keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRjUdLDqlmt",
        "outputId": "8bd9dc99-1439-4299-8f8f-e090c09081e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__ >= '2.0.0'  # Comprobamos que estamos usando al menos la versión 2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifOEj4QTFDju"
      },
      "source": [
        "El módulo keras.datasets contiene un dataset con imágenes de ropa que usaremos para este proyecto.\\\n",
        "Las imágenes se encuentran convenientemente etiquetadas y en formato mnist.\\\n",
        "A continuación almacenamos en memoria las imágenes de entrenamiento  e imágenes de test (junto con sus etiquetas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA0GDH69qlmu",
        "outputId": "e38d224f-7dcf-49c7-921c-93dfd4ca57aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (60000, 28, 28) (60000,)\n",
            "<class 'numpy.ndarray'> (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "print(type(train_images), train_images.shape, train_labels.shape)\n",
        "print(type(test_images), test_images.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7MkuUAZqlmv",
        "outputId": "cbbc5025-b1ef-44ab-c4d0-d51963575558"
      },
      "source": [
        "Observamos que train_images y test_images son numpy.arrays de 3 dimensiones.\\\n",
        "60_000 imágenes de 28x28 pixels para el entrenamiento (60_000 etiquetas).\\\n",
        "10_000 imágenes de 28x28 pixels para test (10_000 etiquetas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lWXf4WHdUh3"
      },
      "source": [
        "Comprobamos que las etiquetas van de 0 a 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "fLk8C6abdUh3",
        "outputId": "06186abe-fe43-404c-c774-82fc202f0e66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ],
      "source": [
        "print(set(train_labels))\n",
        "print(set(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_ygXtzdUh3"
      },
      "source": [
        "Echemos un vistazo a alguna imagen del set de entrenamiento (son numpy arrays 2D)\\\n",
        "Por ejemplo la número 30_000\\\n",
        "Para ello importamos numpy, de forma que podamos cambiar las opciones de impresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi2DmUJ5qlmv",
        "outputId": "2aade37e-7804-494b-d051-99121fdf8dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0 118 204 181 175 213 199 168 197 111   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 173 225 185 179 225 158 142 227 173   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 170 229 226 226 233 151 167 234 158   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 194 222 212 226 222 240 218 230 163   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 222 210 207 211 207 208 231 147   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 188 220 209 210 211 215 208 230 144   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 232 214 220 212 220 213 239 158   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 232 217 216 215 219 216 238 160   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 185 231 218 221 215 218 214 238 170   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 188 233 215 220 219 219 216 238 169   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 169 240 219 221 222 228 214 243 114   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 128 255 214 218 206 205 225 233  53   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 200 229 218 221 219 211 217 228 204   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  34 230 214 217 216 218 218 220 217 231  42   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  94 236 213 219 219 218 215 219 213 234 110   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 167 234 212 218 218 219 212 225 215 231 170   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 200 230 213 216 218 221 211 224 214 228 213   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 192 228 213 216 218 222 213 224 215 221 200   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 202 225 216 214 219 215 219 225 215 219 208   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 215 224 214 215 221 213 217 220 215 216 216   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  26 232 214 218 213 226 212 216 225 215 211 224  27   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  59 234 214 220 214 225 211 213 227 216 212 228  51   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  67 233 214 221 213 227 209 215 228 216 211 228  56   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  92 234 215 219 215 226 208 214 227 215 211 225  42   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 116 236 215 218 211 230 213 212 229 215 211 228  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 140 231 218 221 221 236 204 219 224 221 219 227 132   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 107 200 193 205 194 217 213 218 248 202 172 227 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  21 108 142 146 125 173 141  94 152 154  89   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=145)\n",
        "print(np.matrix(train_images[30_000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_bUss0edUh4"
      },
      "source": [
        "A simple vista ningún problema\\\n",
        "Los valores de la matriz 2D asociada a la imagen están entre 0 y 255.\\\n",
        "Podemos ver su etiqueta asociada, 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a9GvqdTqlmv",
        "outputId": "b00941bd-362e-4675-8405-8cc1d03778b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "print(train_labels[30_000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iUyaT4FdUh4"
      },
      "source": [
        "Viendo la documentación sabemos que se trata de un vestido por ser el valor 3. (3: Dress)\\\n",
        "No obstante podemos usar el paquete matplotlib para ver como es la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "vq3OWBIgqlmv",
        "outputId": "d4fd302d-7128-4443-e5ec-06975b7a3a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ropa = train_images[30000]\n",
        "plt.imshow(ropa, cmap=plt.cm.binary) # el num más bajo se pone en color blanco, y el más alto en negro\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cZYNDGzdUh4"
      },
      "source": [
        "Abrimos también una imagen del set de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "ylVHZ8aYqlmw",
        "outputId": "df9f000a-5ab0-46cc-f802-892ae6964839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdnklEQVR4nO3df2xV9f3H8ddtoZcftrcW7C8pWBBlE6kbk46ofHE0QE2cIH/4awkYg5EVN2ROw6Kibkk3XJzRMPlHYSaCzoQf0WQYLLZMLWygjBFdB6QKrj/ALr23tHDB9vP9g3DnFRA+x3v7bsvzkZyEe+9597z74XBfnN7b9w0555wAAOhlGdYNAAAuTgQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATAyybuDrenp61NTUpOzsbIVCIet2AACenHPq6OhQcXGxMjLOfZ3T5wKoqalJJSUl1m0AAL6lQ4cOadSoUed8vM8FUHZ2tqRTjefk5Bh3AwDwFYvFVFJSkng+P5e0BdDKlSv1zDPPqKWlRWVlZXrhhRc0ZcqU89ad/rFbTk4OAQQA/dj5XkZJy5sQXn/9dS1dulTLly/Xhx9+qLKyMs2aNUuHDx9Ox+EAAP1QWgLo2Wef1cKFC3Xvvffqu9/9rlatWqVhw4bp5ZdfTsfhAAD9UMoD6MSJE9q1a5cqKir+d5CMDFVUVKi+vv6M/ePxuGKxWNIGABj4Uh5AX3zxhbq7u1VQUJB0f0FBgVpaWs7Yv7q6WpFIJLHxDjgAuDiY/yLqsmXLFI1GE9uhQ4esWwIA9IKUvwtu5MiRyszMVGtra9L9ra2tKiwsPGP/cDiscDic6jYAAH1cyq+AsrKyNHnyZNXU1CTu6+npUU1NjaZOnZrqwwEA+qm0/B7Q0qVLNX/+fP3gBz/QlClT9Nxzz6mzs1P33ntvOg4HAOiH0hJAd9xxh44cOaInnnhCLS0tuu6667R58+Yz3pgAALh4hZxzzrqJr4rFYopEIopGo0xCAIB+6EKfx83fBQcAuDgRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARMoD6Mknn1QoFEraJkyYkOrDAAD6uUHp+KLXXHON3nnnnf8dZFBaDgMA6MfSkgyDBg1SYWFhOr40AGCASMtrQPv27VNxcbHGjh2re+65RwcPHjznvvF4XLFYLGkDAAx8KQ+g8vJyrVmzRps3b9aLL76oxsZG3XTTTero6Djr/tXV1YpEIomtpKQk1S0BAPqgkHPOpfMA7e3tGjNmjJ599lndd999Zzwej8cVj8cTt2OxmEpKShSNRpWTk5PO1gAAaRCLxRSJRM77PJ72dwfk5ubqqquu0v79+8/6eDgcVjgcTncbAIA+Ju2/B3T06FEdOHBARUVF6T4UAKAfSXkAPfzww6qrq9Onn36qDz74QHPnzlVmZqbuuuuuVB8KANCPpfxHcJ9//rnuuusutbW16bLLLtONN96o7du367LLLkv1oQAA/VjKA+i1115L9ZcEAAxAzIIDAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgIu0fSAcA59Ld3e1dk5Hh///mUCjkXRPUVz/h+UIF+VDOffv2eddI0vjx4wPVpQNXQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE0zDBr4l51yv1ASZAv2f//zHu0aS6uvrvWsqKyu9a4YPH+5d09cFmWwdxPr16wPVPfrooynuJDiugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgGClgIMhg0SD++te/BqrbsWOHd01TU5N3zc9+9jPvmr7u8OHD3jVvv/22d012drZ3TV/DFRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATDCMFvqXu7m7vmkGD/P/p/f3vf/eu+eSTT7xrJKmgoMC7Zt++fd41c+fO9a659NJLvWuOHz/uXSNJY8aM8a5pa2vzronFYt41l19+uXdNX8MVEADABAEEADDhHUDbtm3TrbfequLiYoVCIW3cuDHpceecnnjiCRUVFWno0KGqqKgIdGkOABjYvAOos7NTZWVlWrly5VkfX7FihZ5//nmtWrVKO3bs0PDhwzVr1qzAP4MFAAxM3q+EVlZWqrKy8qyPOef03HPP6bHHHtNtt90mSXrllVdUUFCgjRs36s477/x23QIABoyUvgbU2NiolpYWVVRUJO6LRCIqLy9XfX39WWvi8bhisVjSBgAY+FIaQC0tLZLOfAtnQUFB4rGvq66uViQSSWwlJSWpbAkA0EeZvwtu2bJlikajie3QoUPWLQEAekFKA6iwsFCS1NramnR/a2tr4rGvC4fDysnJSdoAAANfSgOotLRUhYWFqqmpSdwXi8W0Y8cOTZ06NZWHAgD0c97vgjt69Kj279+fuN3Y2Kjdu3crLy9Po0eP1pIlS/Sb3/xG48ePV2lpqR5//HEVFxdrzpw5qewbANDPeQfQzp07dfPNNyduL126VJI0f/58rVmzRo888og6Ozt1//33q729XTfeeKM2b96sIUOGpK5rAEC/F3LOOesmvioWiykSiSgajfJ6EHpdT0+Pd01Ghv9Psjs7O71rnn76ae+acDjsXSMF+54+/fRT75r29nbvmt4cRhrk72nUqFHeNUGehoP+3T733HOB6nxc6PO4+bvgAAAXJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACe+PY0DfFmSqbigUCnSsIJOjgxwrSE13d7d3jSRlZmYGqvO1atUq75qCggLvmqAfg/LZZ5951wSZOB3ke/ryyy+9a4Ke48OHD/euCTKlOhqNetfE43HvGinYhO8g63AhuAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggmGkvaS3hoQGHboYREZG7/z/Jchg0d4aKipJ69at865paWnxrvne977nXRNkcKcktbe3e9fk5eV514wYMcK75osvvvCuOXr0qHeNFHz9fAV5fujq6gp0rH379nnXXHfddYGOdT5cAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBMNJe0ltDQnt6enqlRgo28DPIOvTmYNGXX37Zu+bf//63d01JSYl3TVtbm3dNkCGXknTs2DHvmssvv9y7pqOjw7smyDk0bNgw7xpJOn78uHdNbw0eDurtt9/2rmEYKQBgQCGAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDioh5GGnQIZxBBhg0GGWqYkeH/f4ogNb2pqanJu2b9+vWBjhVkCOf48eO9a44ePepdE4/HvWuCDDCVpMGDB3vXBDnHu7q6vGuCCHqOh8PhXjnW8OHDvWuCDjB9//33A9WlQ99+5gEADFgEEADAhHcAbdu2TbfeequKi4sVCoW0cePGpMcXLFigUCiUtM2ePTtV/QIABgjvAOrs7FRZWZlWrlx5zn1mz56t5ubmxLZu3bpv1SQAYODxfhNCZWWlKisrv3GfcDiswsLCwE0BAAa+tLwGVFtbq/z8fF199dVatGjRN74TJx6PKxaLJW0AgIEv5QE0e/ZsvfLKK6qpqdHvfvc71dXVqbKyUt3d3Wfdv7q6WpFIJLGVlJSkuiUAQB+U8t8DuvPOOxN/vvbaazVp0iSNGzdOtbW1mjFjxhn7L1u2TEuXLk3cjsVihBAAXATS/jbssWPHauTIkdq/f/9ZHw+Hw8rJyUnaAAADX9oD6PPPP1dbW5uKiorSfSgAQD/i/SO4o0ePJl3NNDY2avfu3crLy1NeXp6eeuopzZs3T4WFhTpw4IAeeeQRXXnllZo1a1ZKGwcA9G/eAbRz507dfPPNidunX7+ZP3++XnzxRe3Zs0d/+tOf1N7eruLiYs2cOVO//vWvA81UAgAMXN4BNH369G8ckvn2229/q4ZO6+7uPuc7584mMzPT+xh9fQhn0GGDvo4cORKo7tNPP/WuaWho8K5pbm72rsnKyvKukRToNcj29nbvmiC/bnDy5EnvmiADTKVg/56CnA9ffvmld01ubq53TdDzwec56LQgQ4SHDh3qXROkN0m65JJLvGv27t3rtf+FDtvt28/AAIABiwACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgIuUfyZ0qmZmZgSby+mhtbQ1U99lnn3nXdHZ29krNsWPHvGsaGxu9aySpq6vLu2bQIP9TLjs727ump6fHu0aSotGod02QNQ+yDkHWO8iUZUmBPj7lxIkT3jVBPqgyyCTxIGsnSZdeeql3zYVOgv6q//73v941QaZaS1JLS4t3jW9/F/rcxRUQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE312GKmvd955x7umqakp0LGCDJI8cuSId013d7d3TZABrkG+HynYkNAggxqDDE90znnXSFI8HveuCTKwMsiw1CBrF+QckqThw4d71wQZjpmbm+tdE+TfUm8Kcj5kZPhfCwQZgisFGxrr+xxxoftzBQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEnx1GWlNT4zUQ8aWXXvI+xoQJE7xrJKmoqMi7JsjgziADK7Oysrxrgg6sDDLwM8g6BBmeGGS4oyR1dHR41wRZhyCDJEOhkHdN0L/bIANgW1tbvWs+/vhj75og50PQdQgiyFDWzs5O75ohQ4Z410jB+svPz/fa/0L/HXEFBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwESfHUY6efJk5eTkXPD+27dv9z7GP//5T+8aSXrvvfcC1fkaPHiwd02QYZ95eXneNUHrIpGId02Q4ZNBBoRKUltbm3dNQ0ODd01XV5d3TSwW864JMsBUkv7xj39410yaNMm75oorrvCu2bJli3dNPB73rpGCD7X1NWiQ/1NxcXFxoGP5PK+e5juk9+jRoxe0H1dAAAATBBAAwIRXAFVXV+v6669Xdna28vPzNWfOnDN+/HD8+HFVVVVpxIgRuuSSSzRv3rxAnxMCABjYvAKorq5OVVVV2r59u7Zs2aKTJ09q5syZSR+m9NBDD+nNN9/UG2+8obq6OjU1Nen2229PeeMAgP7N65WvzZs3J91es2aN8vPztWvXLk2bNk3RaFQvvfSS1q5dqx/96EeSpNWrV+s73/mOtm/frh/+8Iep6xwA0K99q9eAotGopP+9G2rXrl06efKkKioqEvtMmDBBo0ePVn19/Vm/RjweVywWS9oAAANf4ADq6enRkiVLdMMNN2jixImSTn2OfFZWlnJzc5P2LSgoOOdnzFdXVysSiSS2kpKSoC0BAPqRwAFUVVWlvXv36rXXXvtWDSxbtkzRaDSxHTp06Ft9PQBA/xDoF1EXL16st956S9u2bdOoUaMS9xcWFurEiRNqb29PugpqbW1VYWHhWb9WOBxWOBwO0gYAoB/zugJyzmnx4sXasGGDtm7dqtLS0qTHJ0+erMGDB6umpiZxX0NDgw4ePKipU6empmMAwIDgdQVUVVWltWvXatOmTcrOzk68rhOJRDR06FBFIhHdd999Wrp0qfLy8pSTk6MHH3xQU6dO5R1wAIAkXgH04osvSpKmT5+edP/q1au1YMECSdIf/vAHZWRkaN68eYrH45o1a5b++Mc/pqRZAMDAEXJBpzamSSwWUyQSUTQaDTQ0rzdc6KC9r9qxY4d3TZAhlx988IF3zZEjR7xrpGDDMb/6S8sXKsgpGnQIZ5Dhk0GGsk6YMMG75qu/3nChbrnlFu8aSRoyZEigut7w4x//2Lvm4MGDgY41YsQI75ogz1tBhggHGWAqKdBr7r///e+99o/FYiouLj7v8ziz4AAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJpiGDQBIqQt9HucKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMIrgKqrq3X99dcrOztb+fn5mjNnjhoaGpL2mT59ukKhUNL2wAMPpLRpAED/5xVAdXV1qqqq0vbt27VlyxadPHlSM2fOVGdnZ9J+CxcuVHNzc2JbsWJFSpsGAPR/g3x23rx5c9LtNWvWKD8/X7t27dK0adMS9w8bNkyFhYWp6RAAMCB9q9eAotGoJCkvLy/p/ldffVUjR47UxIkTtWzZMnV1dZ3za8TjccVisaQNADDweV0BfVVPT4+WLFmiG264QRMnTkzcf/fdd2vMmDEqLi7Wnj179Oijj6qhoUHr168/69eprq7WU089FbQNAEA/FXLOuSCFixYt0l/+8he99957GjVq1Dn327p1q2bMmKH9+/dr3LhxZzwej8cVj8cTt2OxmEpKShSNRpWTkxOkNQCAoVgspkgkct7n8UBXQIsXL9Zbb72lbdu2fWP4SFJ5ebkknTOAwuGwwuFwkDYAAP2YVwA55/Tggw9qw4YNqq2tVWlp6Xlrdu/eLUkqKioK1CAAYGDyCqCqqiqtXbtWmzZtUnZ2tlpaWiRJkUhEQ4cO1YEDB7R27VrdcsstGjFihPbs2aOHHnpI06ZN06RJk9LyDQAA+iev14BCodBZ71+9erUWLFigQ4cO6Sc/+Yn27t2rzs5OlZSUaO7cuXrssccu+PWcC/3ZIQCgb0rLa0Dny6qSkhLV1dX5fEkAwEWKWXAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABODrBv4OuecJCkWixl3AgAI4vTz9+nn83PpcwHU0dEhSSopKTHuBADwbXR0dCgSiZzz8ZA7X0T1sp6eHjU1NSk7O1uhUCjpsVgsppKSEh06dEg5OTlGHdpjHU5hHU5hHU5hHU7pC+vgnFNHR4eKi4uVkXHuV3r63BVQRkaGRo0a9Y375OTkXNQn2GmswymswymswymswynW6/BNVz6n8SYEAIAJAggAYKJfBVA4HNby5csVDoetWzHFOpzCOpzCOpzCOpzSn9ahz70JAQBwcehXV0AAgIGDAAIAmCCAAAAmCCAAgIl+E0ArV67UFVdcoSFDhqi8vFx/+9vfrFvqdU8++aRCoVDSNmHCBOu20m7btm269dZbVVxcrFAopI0bNyY97pzTE088oaKiIg0dOlQVFRXat2+fTbNpdL51WLBgwRnnx+zZs22aTZPq6mpdf/31ys7OVn5+vubMmaOGhoakfY4fP66qqiqNGDFCl1xyiebNm6fW1lajjtPjQtZh+vTpZ5wPDzzwgFHHZ9cvAuj111/X0qVLtXz5cn344YcqKyvTrFmzdPjwYevWet0111yj5ubmxPbee+9Zt5R2nZ2dKisr08qVK8/6+IoVK/T8889r1apV2rFjh4YPH65Zs2bp+PHjvdxpep1vHSRp9uzZSefHunXrerHD9Kurq1NVVZW2b9+uLVu26OTJk5o5c6Y6OzsT+zz00EN688039cYbb6iurk5NTU26/fbbDbtOvQtZB0lauHBh0vmwYsUKo47PwfUDU6ZMcVVVVYnb3d3drri42FVXVxt21fuWL1/uysrKrNswJclt2LAhcbunp8cVFha6Z555JnFfe3u7C4fDbt26dQYd9o6vr4Nzzs2fP9/ddtttJv1YOXz4sJPk6urqnHOn/u4HDx7s3njjjcQ+n3zyiZPk6uvrrdpMu6+vg3PO/d///Z/7+c9/btfUBejzV0AnTpzQrl27VFFRkbgvIyNDFRUVqq+vN+zMxr59+1RcXKyxY8fqnnvu0cGDB61bMtXY2KiWlpak8yMSiai8vPyiPD9qa2uVn5+vq6++WosWLVJbW5t1S2kVjUYlSXl5eZKkXbt26eTJk0nnw4QJEzR69OgBfT58fR1Oe/XVVzVy5EhNnDhRy5YtU1dXl0V759TnhpF+3RdffKHu7m4VFBQk3V9QUKB//etfRl3ZKC8v15o1a3T11VerublZTz31lG666Sbt3btX2dnZ1u2ZaGlpkaSznh+nH7tYzJ49W7fffrtKS0t14MAB/epXv1JlZaXq6+uVmZlp3V7K9fT0aMmSJbrhhhs0ceJESafOh6ysLOXm5ibtO5DPh7OtgyTdfffdGjNmjIqLi7Vnzx49+uijamho0Pr16w27TdbnAwj/U1lZmfjzpEmTVF5erjFjxujPf/6z7rvvPsPO0BfceeediT9fe+21mjRpksaNG6fa2lrNmDHDsLP0qKqq0t69ey+K10G/ybnW4f7770/8+dprr1VRUZFmzJihAwcOaNy4cb3d5ln1+R/BjRw5UpmZmWe8i6W1tVWFhYVGXfUNubm5uuqqq7R//37rVsycPgc4P840duxYjRw5ckCeH4sXL9Zbb72ld999N+njWwoLC3XixAm1t7cn7T9Qz4dzrcPZlJeXS1KfOh/6fABlZWVp8uTJqqmpSdzX09OjmpoaTZ061bAze0ePHtWBAwdUVFRk3YqZ0tJSFRYWJp0fsVhMO3bsuOjPj88//1xtbW0D6vxwzmnx4sXasGGDtm7dqtLS0qTHJ0+erMGDByedDw0NDTp48OCAOh/Otw5ns3v3bknqW+eD9bsgLsRrr73mwuGwW7Nmjfv444/d/fff73Jzc11LS4t1a73qF7/4hautrXWNjY3u/fffdxUVFW7kyJHu8OHD1q2lVUdHh/voo4/cRx995CS5Z5991n300Ufus88+c84599vf/tbl5ua6TZs2uT179rjbbrvNlZaWumPHjhl3nlrftA4dHR3u4YcfdvX19a6xsdG988477vvf/74bP368O378uHXrKbNo0SIXiURcbW2ta25uTmxdXV2JfR544AE3evRot3XrVrdz5043depUN3XqVMOuU+9867B//3739NNPu507d7rGxka3adMmN3bsWDdt2jTjzpP1iwByzrkXXnjBjR492mVlZbkpU6a47du3W7fU6+644w5XVFTksrKy3OWXX+7uuOMOt3//fuu20u7dd991ks7Y5s+f75w79Vbsxx9/3BUUFLhwOOxmzJjhGhoabJtOg29ah66uLjdz5kx32WWXucGDB7sxY8a4hQsXDrj/pJ3t+5fkVq9endjn2LFj7qc//am79NJL3bBhw9zcuXNdc3OzXdNpcL51OHjwoJs2bZrLy8tz4XDYXXnlle6Xv/yli0ajto1/DR/HAAAw0edfAwIADEwEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBM/D9uRNWxsj7EigAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ropa = test_images[0]\n",
        "plt.imshow(ropa, cmap=plt.cm.binary) # Veamos el elemento 0 del set de tests y pintémoslo con matplotlib\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNu3uJWTdUh4"
      },
      "source": [
        "Un zapato, no cabe duda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "TmJs2BINqlmw",
        "outputId": "97b854aa-01a3-43e4-ae5c-331335e6be67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "print(test_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcVJhxOxdUh5"
      },
      "source": [
        "Así lo indica su etiqueta (9: shoe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función de keras keras.layers.Flatten() nos podría ser útil para aplanar la entrada .... (falta info)"
      ],
      "metadata": {
        "id": "VVDGHuPNvTqL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzT5-LModUh5"
      },
      "source": [
        "## Cuestiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7SvF5s6dUh5"
      },
      "source": [
        "### 1. Configurar y entrenar los siguientes modelos de red de neuronas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBIhnqmcdUh5"
      },
      "source": [
        "A continuación establecemos los parámetros de configuración solicitados\\\n",
        "Utilizaremos namedtuples como contenedores de las configuraciones\\\n",
        "Nota: Las configuraciones de este tipo recomendaríamos tenerlas en un script aparte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "nGe7bDl5dUh5",
        "outputId": "dfc0f351-f159-48df-8eb2-f1018636ed72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param_RN(neuronas_capa1=10, funcion_activacion='relu', optimizador='sgd')\n"
          ]
        }
      ],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "neuronas_capa1 = (10, 10, 10, 10, 512, 512, 512, 512)\n",
        "funcion_activacion = (\"relu\", \"relu\", \"sigmoid\", \"sigmoid\", \"relu\", \"relu\", \"sigmoid\", \"sigmoid\")\n",
        "optimizador = (\"sgd\", \"rmsprop\", \"sgd\", \"rmsprop\", \"sgd\", \"rmsprop\", \"sgd\", \"rmsprop\")\n",
        "\n",
        "param_rn = namedtuple(\"Param_RN\",\n",
        "                      [\"neuronas_capa1\",\"funcion_activacion\",\"optimizador\"])\n",
        "\n",
        "rn_configs = [param_rn(*params) for params in zip(neuronas_capa1,\n",
        "                                                  funcion_activacion,\n",
        "                                                  optimizador)]\n",
        "print(rn_configs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEc03ZbRdUh5"
      },
      "source": [
        "Adicionalmente se utilizará:\n",
        "* función de perdida 'categorical_crossentropy'\n",
        "* métrica de precisión\n",
        "* 5 épocas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkAsMhuXdUh5"
      },
      "source": [
        "**CONSTRUIMOS LA RNA**\n",
        "- **Capa** (**layers**) es el **componente básico de las redes neuronales**. => Es un **filtro** de datos (módulo de procesamiento de datos).Entran datos y salen con una forma más útil para el objetivo del problema a resolver. => **Destilación de datos**\n",
        "\n",
        "El tipo de modelo para nuestras redes será secuencial y utilizaremos 2 capas densas (cada neurona está conectada a todas las demás de esa capa).\n",
        "Las redes constarán de dos capas densas:\n",
        "* **Capa 1** contiene el número de neuronas y su función de activación (ambos especificados en el enunciado)\n",
        "* **Capa 2** contiene 10 neuronas (una para cada tipo de ropa) y función de activación softmax.\n",
        "Esta última capa nos servirá para saber como de bien lo ha hecho la red, al devolvernos una matriz de 10 puntuaciones de probabilidad (sumando 1)\n",
        "\n",
        "La puntuación será la probabilidad de que la imagen pertenezca a una de nuestras clases de 10 tipos de prendas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.- CONSTRUIMOS LA ARQUITECTURA DE LA RED\n",
        "from keras import models  # importamos de keras las librerías de modelos y de capas (layers)\n",
        "from keras import layers\n",
        "\n",
        "networks = []\n",
        "for config in rn_configs:\n",
        "  network = models.Sequential()\n",
        "  # Primera capa (configuración enunciado)\n",
        "  network.add(layers.Dense(units=config.neuronas_capa1,\n",
        "                           activation=config.funcion_activacion,\n",
        "                           input_shape=(28,28,)))\n",
        "  # Segunda capa (10 neuronas y softmax)\n",
        "  network.add(layers.Dense(10, activation='softmax'))\n",
        "  networks.append(network)\n",
        "\n",
        "# Por ejemplo, vemos la primera network de nuestra lista de networks\n",
        "networks[0].summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzV0Wi66AGug",
        "outputId": "059fc11c-5b2e-4d5f-fad2-3c296cfe3061"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_128 (Dense)           (None, 28, 10)            290       \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 28, 10)            110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 400 (1.56 KB)\n",
            "Trainable params: 400 (1.56 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que para la primera red neuronal (networks[0]), tenemos un total de 7960 parámetros que se obtienen como resultado de *nº de neuronas x nº de entradas + sesgos* de cada capa ya que las capas son densas.\n",
        "\n",
        "*   **Capa 1:** 10 x 784 + 10 = 7850\n",
        "*   **Capa 2:** 10 x 10 + 10 = 110\n",
        "*   **TOTAL:** 7850 + 110 = 7960"
      ],
      "metadata": {
        "id": "LGNdAEL_EKvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para terminar de preparar la red, debemos elegir:\n",
        "- Una **función de pérdida**: utilizaremos la función de pérdida `categorical_crossentropy` que mide la discrepancia entre las predicciones de un modelo y las respuestas reales en problemas de clasificación con múltiples categorías. Calcula la diferencia entre las distribuciones de probabilidad predichas y las verdaderas, utilizando la entropía cruzada como métrica.\n",
        "\n",
        "- Un **optimizador**: dependiendo del caso usaremos los optimizadores `sgd` o `rmsprop`.\n",
        "  \n",
        "\n",
        "1.   SGD (Descenso de Gradiente Estocástico): Actualiza los pesos en dirección opuesta al gradiente de la función de pérdida. \"Estocástico\" significa que utiliza muestras de datos de manera aleatoria para calcular el gradiente, lo que puede ayudar a evitar mínimos locales.\n",
        "2.   RMSprop (Root Mean Square Propagation): Modifica el SGD para adaptarse a tasas de aprendizaje diferentes para cada parámetro. Almacena una media móvil ponderada de los cuadrados de los gradientes anteriores y utiliza esta información para normalizar la tasa de aprendizaje.\n",
        "\n",
        "\n",
        "- **Métricas** para monitorizar durante el entrenamiento y las pruebas. Solo nos preocuparemos por la **precisión** `accuracy` (la fracción de las imágenes que fueron clasificado)."
      ],
      "metadata": {
        "id": "k5s8MCtJRYCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el optimizador, la función de pérdida y las métricas\n",
        "for i, config in enumerate(rn_configs):\n",
        "  networks[i].compile(optimizer=config.optimizador,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy']) # si de cada 10 imágenes acierta 8, tiene un accuracy del 80%"
      ],
      "metadata": {
        "id": "FZFKNvdaLKnY"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función de pérdida crossentropy se utiliza como señal\n",
        "de retroalimentación para aprender los tensores de peso y que la fase de\n",
        "entrenamiento intentará minimizar.\\\n",
        "La reducción de la pérdida se produce mediante el descenso de gradiente\n",
        "estocástico minilote, cuyas reglas exactas están gobernadas por el optimizador\n",
        "'rmsprop'."
      ],
      "metadata": {
        "id": "RrjL3Y6AVfAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalización de los datos\n",
        "para facilitar que converja el proceso de entrenamiento preparamos los datos de imagen con alguna transformación. Los tensores transformados tienen la misma cantidad de datos total que el tensor inicial.\n",
        "\n",
        "Utilizaremos la función"
      ],
      "metadata": {
        "id": "MU9pZNHbXARm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))  # TODO: usar flatten decir que es y este equivalente\n",
        "print(train_images.shape)\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=145)\n",
        "print(np.matrix(train_images[3000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMMrQ03KXVpH",
        "outputId": "c67ce139-7935-4b28-9dc8-3d8cc8a77f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "60000\n",
            "(60000, 784)\n",
            "[[  0   0   0   0   0   0   0   0   1   1   0   0 120 131  91 147  30   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
            "    3   0   0   0   0 251 199 172 195 152   0   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0  43 124 193 166 239\n",
            "  255 216 172 228 126  61   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  96 167 155 159 171 178 211 215 210 196 189 158 164 159\n",
            "  108   0   0   0   0   0   0   0   0   0   0   0   0  83 157 131 117 120 148 148 145 178 159 174 160 123 132 142 172  38   0   0   0   0   0\n",
            "    0   0   0   0   0   0 159 128 118 120 122 112  93 124 161 109 128 128 129 146 138 167 122   0   0   0   0   0   0   0   0   0   0   0 171\n",
            "  135 120 114 118 119 107 125 123 117 124 124 119 145 147 166 148   0   0   0   0   0   0   0   0   0   0   4 171 138 126 120 117 118 102 122\n",
            "  145 111 120 122 120 152 154 155 170   0   0   0   0   0   0   0   0   0   0  31 170 129 138 125 113 106 103 118 137 108 135 130 158 182 138\n",
            "  143 186   0   0   0   0   0   0   0   0   0   0  58 163 114 137 143 119 103 100 109 118 109 129 134 172 181 131 136 190   0   0   0   0   0\n",
            "    0   0   0   0   0  76 160 113 141 148 128 111 101 116 137 111 131 142 167 183 136 120 186  12   0   0   0   0   0   0   0   0   0 100 148\n",
            "  108 147 147 134 120 105 116 131 116 136 137 165 192 137 113 187  30   0   0   0   0   0   0   0   0   0 114 143 108 158 147 130 125 106 114\n",
            "  122 119 129 134 160 196 136 109 182  51   0   0   0   0   0   0   0   0   0 120 140 117 151 148 131 124 109 120 143 120 130 128 159 188 111\n",
            "  108 178  66   0   0   0   0   0   0   0   0   0 125 129 128 112 145 140 122 113 118 134 117 132 128 166 157  91 120 170  74   0   0   0   0\n",
            "    0   0   0   0   0 126 123 138  74 140 143 124 111 112 126 120 130 129 175 120  88 128 164  91   0   0   0   0   0   0   0   0   0 124 123\n",
            "  157  45 145 143 124 113 119 148 122 131 129 183  90  73 137 155  99   0   0   0   0   0   0   0   0   0 118 122 167   0 143 149 122 112 118\n",
            "  137 116 132 126 183  73  50 152 147 101   0   0   0   0   0   0   0   0   0 111 128 164   0 142 151 122 111 117 132 120 136 125 182  90  18\n",
            "  164 145 107   0   0   0   0   0   0   0   0   0 109 132 158   0 146 148 120 108 125 157 120 136 131 176 111   0 164 143 118   0   0   0   0\n",
            "    0   0   0   0   0 111 141 140   0 148 149 120 114 123 137 124 137 131 171 135   0 157 147 125   0   0   0   0   0   0   0   0   0 111 154\n",
            "  111   0 155 148 118 116 124 143 123 131 129 167 155   0 129 157 129   0   0   0   0   0   0   0   0   0 109 155  87   0 157 145 119 117 126\n",
            "  154 126 130 123 161 160   0  97 163 130   0   0   0   0   0   0   0   0   0 124 142  54   0 149 141 119 119 124 136 129 126 120 153 175   0\n",
            "   76 145 137   0   0   0   0   0   0   0   0   0 136 151  47   0 149 137 119 118 126 143 132 130 123 153 172   0  66 148 154   0   0   0   0\n",
            "    0   0   0   0   0 109 174  48   0 154 138 119 117 124 138 130 129 125 159 167   0  58 174 128   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  85 182 147 136 143 158 146 148 153 199  70   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26  54  72  83\n",
            "   96  85  80  61  14   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "print(np.matrix(train_images[3000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2THPuJzYi0S",
        "outputId": "388e72f6-1eca-4fa7-a320-27e18007181c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 60000,\n",
              " (60000, 784),\n",
              " array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.47, 0.51, 0.36, 0.58, 0.12, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.98, 0.78, 0.67, 0.76, 0.6 , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.49, 0.76, 0.65,\n",
              "        0.94, 1.  , 0.85, 0.67, 0.89, 0.49, 0.24, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.38,\n",
              "        0.65, 0.61, 0.62, 0.67, 0.7 , 0.83, 0.84, 0.82, 0.77, 0.74, 0.62, 0.64, 0.62, 0.42, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.33, 0.62, 0.51, 0.46, 0.47, 0.58, 0.58, 0.57, 0.7 , 0.62, 0.68, 0.63, 0.48, 0.52, 0.56, 0.67, 0.15, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.62, 0.5 , 0.46, 0.47, 0.48, 0.44, 0.36, 0.49, 0.63, 0.43, 0.5 , 0.5 , 0.51, 0.57, 0.54,\n",
              "        0.65, 0.48, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.67, 0.53, 0.47, 0.45, 0.46, 0.47, 0.42, 0.49, 0.48, 0.46,\n",
              "        0.49, 0.49, 0.47, 0.57, 0.58, 0.65, 0.58, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.67, 0.54, 0.49, 0.47, 0.46,\n",
              "        0.46, 0.4 , 0.48, 0.57, 0.44, 0.47, 0.48, 0.47, 0.6 , 0.6 , 0.61, 0.67, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12,\n",
              "        0.67, 0.51, 0.54, 0.49, 0.44, 0.42, 0.4 , 0.46, 0.54, 0.42, 0.53, 0.51, 0.62, 0.71, 0.54, 0.56, 0.73, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.23, 0.64, 0.45, 0.54, 0.56, 0.47, 0.4 , 0.39, 0.43, 0.46, 0.43, 0.51, 0.53, 0.67, 0.71, 0.51, 0.53, 0.75, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.63, 0.44, 0.55, 0.58, 0.5 , 0.44, 0.4 , 0.45, 0.54, 0.44, 0.51, 0.56, 0.65,\n",
              "        0.72, 0.53, 0.47, 0.73, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.58, 0.42, 0.58, 0.58, 0.53, 0.47, 0.41, 0.45,\n",
              "        0.51, 0.45, 0.53, 0.54, 0.65, 0.75, 0.54, 0.44, 0.73, 0.12, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.56, 0.42, 0.62,\n",
              "        0.58, 0.51, 0.49, 0.42, 0.45, 0.48, 0.47, 0.51, 0.53, 0.63, 0.77, 0.53, 0.43, 0.71, 0.2 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.47, 0.55, 0.46, 0.59, 0.58, 0.51, 0.49, 0.43, 0.47, 0.56, 0.47, 0.51, 0.5 , 0.62, 0.74, 0.44, 0.42, 0.7 , 0.26, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.51, 0.5 , 0.44, 0.57, 0.55, 0.48, 0.44, 0.46, 0.53, 0.46, 0.52, 0.5 , 0.65, 0.62, 0.36, 0.47,\n",
              "        0.67, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.48, 0.54, 0.29, 0.55, 0.56, 0.49, 0.44, 0.44, 0.49, 0.47, 0.51,\n",
              "        0.51, 0.69, 0.47, 0.35, 0.5 , 0.64, 0.36, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.48, 0.62, 0.18, 0.57, 0.56, 0.49,\n",
              "        0.44, 0.47, 0.58, 0.48, 0.51, 0.51, 0.72, 0.35, 0.29, 0.54, 0.61, 0.39, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.46, 0.48,\n",
              "        0.65, 0.  , 0.56, 0.58, 0.48, 0.44, 0.46, 0.54, 0.45, 0.52, 0.49, 0.72, 0.29, 0.2 , 0.6 , 0.58, 0.4 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.44, 0.5 , 0.64, 0.  , 0.56, 0.59, 0.48, 0.44, 0.46, 0.52, 0.47, 0.53, 0.49, 0.71, 0.35, 0.07, 0.64, 0.57, 0.42, 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.52, 0.62, 0.  , 0.57, 0.58, 0.47, 0.42, 0.49, 0.62, 0.47, 0.53, 0.51, 0.69, 0.44,\n",
              "        0.  , 0.64, 0.56, 0.46, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.55, 0.55, 0.  , 0.58, 0.58, 0.47, 0.45, 0.48, 0.54,\n",
              "        0.49, 0.54, 0.51, 0.67, 0.53, 0.  , 0.62, 0.58, 0.49, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.6 , 0.44, 0.  , 0.61,\n",
              "        0.58, 0.46, 0.45, 0.49, 0.56, 0.48, 0.51, 0.51, 0.65, 0.61, 0.  , 0.51, 0.62, 0.51, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.43, 0.61, 0.34, 0.  , 0.62, 0.57, 0.47, 0.46, 0.49, 0.6 , 0.49, 0.51, 0.48, 0.63, 0.63, 0.  , 0.38, 0.64, 0.51, 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.56, 0.21, 0.  , 0.58, 0.55, 0.47, 0.47, 0.49, 0.53, 0.51, 0.49, 0.47, 0.6 , 0.69, 0.  , 0.3 , 0.57,\n",
              "        0.54, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.59, 0.18, 0.  , 0.58, 0.54, 0.47, 0.46, 0.49, 0.56, 0.52, 0.51, 0.48,\n",
              "        0.6 , 0.67, 0.  , 0.26, 0.58, 0.6 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.68, 0.19, 0.  , 0.6 , 0.54, 0.47, 0.46,\n",
              "        0.49, 0.54, 0.51, 0.51, 0.49, 0.62, 0.65, 0.  , 0.23, 0.68, 0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.33, 0.71, 0.58, 0.53, 0.56, 0.62, 0.57, 0.58, 0.6 , 0.78, 0.27, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.21, 0.28, 0.33, 0.38, 0.33, 0.31, 0.24, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "metadata": {
        "id": "alIAz6yMYjcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codificaremos categoricamente las etiquetas en one-hot encoding, transformando las etiquetas en un vector de tantos ceros como el número de etiquetas distinta, y que contiene el valor de 1 en el índice que le corresponde al valor de la etiqueta:"
      ],
      "metadata": {
        "id": "7tTSAqxNYhY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparación de las etiquetas\n",
        "import numpy as np\n",
        "from keras import utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_labels[30000] # Posición 0 a 9 donde solo la 3 tiene probabilidad 1.\n",
        "# El número 30000 de entrenamiento es un 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGqy5GUBYw9r",
        "outputId": "7471890e-c0cd-4f5a-e6cc-3d3460ff9188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el array de la etiqueta 30000, el 1 está en la posición 3 ya que se trata del índice 3 (Dress)."
      ],
      "metadata": {
        "id": "fmYxDHVEZEUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento de las redes neuronales\n",
        "\n",
        "\n",
        "*   Nº de épocas: Usaremos 5 épocas (la red pasará 5 veces por el conjunto de datos) para\n",
        "separar el entrenamiento en 5 fases, dividir el entrenamiento en épocas es útil para el registro y la evaluación periódica\n",
        "*   Tamaño del lote (batch size): tomamos paquetes de 128 imágenes, para calcular la media de las pérdidas y ajustar los parámetros cada 128 imágenes.\n",
        "\n"
      ],
      "metadata": {
        "id": "0viqnuRkZV57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "networks[0].fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "# TODO: networks[0].save('nombre')\n",
        "# save the neural network as a SavedModel\n",
        "tf.saved_model.save(networks[0], 'saved_model')\n",
        "\n",
        "# load the neural network from the SavedModel\n",
        "neuronal_network = tf.saved_model.load('saved_model')"
      ],
      "metadata": {
        "id": "SX-IB6BqZca6",
        "outputId": "706e5f81-2c0c-46c7-dc6d-474970da38c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-9b03496eebe5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetworks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3874\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3875\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3876\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3877\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La red empezará a iterar por lo datos de entrenamiento en minilotes de 128\n",
        "muestras, 5 veces. En cada iteración, la red computará los gradientes de\n",
        "los pesos en relación con la pérdida en el lote y ajustará los pesos en\n",
        "consecuencia. Tras estas 5 repeticiones, la red habrá realizado 2.345 ajustes\n",
        "de gradiente (469 por repetición), la pérdida será lo bastante baja como para\n",
        "que la red sea capaz de clasificar números escritos a mano con gran exactitud."
      ],
      "metadata": {
        "id": "KBKPt5CNbWR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for network in networks:\n",
        "  networks[network].fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "id": "5ALikGTVcCCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cada iteración, la red computará los gradientes de los pesos en relación con la pérdida en el lote y ajustará los pesos en consecuencia. Tras estas 5 repeticiones, la red habrá realizado 2.345 ajustes de gradiente (469 por repetición), la pérdida será lo bastante baja como para que la red sea capaz de clasificar números escritos a mano con gran exactitud."
      ],
      "metadata": {
        "id": "7yEdnkcjdy3l"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}